---
search:
  exclude: true
---
# ë¹ ë¥¸ ì‹œì‘

## ì‚¬ì „ ì¤€ë¹„

OpenAI Agents SDKì˜ ê¸°ë³¸ [ë¹ ë¥¸ ì‹œì‘ ì•ˆë‚´](../quickstart.md)ë¥¼ ë”°ë¼ ê°€ìƒ í™˜ê²½ì„ ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ê·¸ëŸ° ë‹¤ìŒ SDKì—ì„œ ì„ íƒì  ìŒì„± ê´€ë ¨ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”:

```bash
pip install 'openai-agents[voice]'
```

## ê°œë…

í•µì‹¬ ê°œë…ì€ [`VoicePipeline`][agents.voice.pipeline.VoicePipeline]ì´ë©°, 3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

1. ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ìŒì„±-í…ìŠ¤íŠ¸ ëª¨ë¸ì„ ì‹¤í–‰
2. ê²°ê³¼ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ë³´í†µ ì—ì´ì „íŠ¸í˜• ì›Œí¬í”Œë¡œì¸ ì½”ë“œë¥¼ ì‹¤í–‰
3. ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸-ìŒì„± ëª¨ë¸ì„ ì‹¤í–‰

```mermaid
graph LR
    %% Input
    A["ğŸ¤ Audio Input"]

    %% Voice Pipeline
    subgraph Voice_Pipeline [Voice Pipeline]
        direction TB
        B["Transcribe (speech-to-text)"]
        C["Your Code"]:::highlight
        D["Text-to-speech"]
        B --> C --> D
    end

    %% Output
    E["ğŸ§ Audio Output"]

    %% Flow
    A --> Voice_Pipeline
    Voice_Pipeline --> E

    %% Custom styling
    classDef highlight fill:#ffcc66,stroke:#333,stroke-width:1px,font-weight:700;

```

## ì—ì´ì „íŠ¸

ë¨¼ì € ì—ì´ì „íŠ¸ë¥¼ ëª‡ ê°œ ì„¤ì •í•´ ë´…ì‹œë‹¤. ì´ SDKë¡œ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ì–´ ë³¸ ì ì´ ìˆë‹¤ë©´ ìµìˆ™í•˜ê²Œ ëŠê»´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ ëª‡ ê°œì™€ í•¸ë“œì˜¤í”„, ê·¸ë¦¬ê³  í•˜ë‚˜ì˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
import asyncio
import random

from agents import (
    Agent,
    function_tool,
)
from agents.extensions.handoff_prompt import prompt_with_handoff_instructions



@function_tool
def get_weather(city: str) -> str:
    """Get the weather for a given city."""
    print(f"[debug] get_weather called with city: {city}")
    choices = ["sunny", "cloudy", "rainy", "snowy"]
    return f"The weather in {city} is {random.choice(choices)}."


spanish_agent = Agent(
    name="Spanish",
    handoff_description="A spanish speaking agent.",
    instructions=prompt_with_handoff_instructions(
        "You're speaking to a human, so be polite and concise. Speak in Spanish.",
    ),
    model="gpt-4.1",
)

agent = Agent(
    name="Assistant",
    instructions=prompt_with_handoff_instructions(
        "You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.",
    ),
    model="gpt-4.1",
    handoffs=[spanish_agent],
    tools=[get_weather],
)
```

## ìŒì„± íŒŒì´í”„ë¼ì¸

ì›Œí¬í”Œë¡œë¡œ [`SingleAgentVoiceWorkflow`][agents.voice.workflow.SingleAgentVoiceWorkflow]ë¥¼ ì‚¬ìš©í•´ ê°„ë‹¨í•œ ìŒì„± íŒŒì´í”„ë¼ì¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.

```python
from agents.voice import SingleAgentVoiceWorkflow, VoicePipeline
pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))
```

## íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```python
import numpy as np
import sounddevice as sd
from agents.voice import AudioInput

# For simplicity, we'll just create 3 seconds of silence
# In reality, you'd get microphone data
buffer = np.zeros(24000 * 3, dtype=np.int16)
audio_input = AudioInput(buffer=buffer)

result = await pipeline.run(audio_input)

# Create an audio player using `sounddevice`
player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)
player.start()

# Play the audio stream as it comes in
async for event in result.stream():
    if event.type == "voice_stream_event_audio":
        player.write(event.data)

```

## í†µí•©

```python
import asyncio
import random

import numpy as np
import sounddevice as sd

from agents import (
    Agent,
    function_tool,
    set_tracing_disabled,
)
from agents.voice import (
    AudioInput,
    SingleAgentVoiceWorkflow,
    VoicePipeline,
)
from agents.extensions.handoff_prompt import prompt_with_handoff_instructions


@function_tool
def get_weather(city: str) -> str:
    """Get the weather for a given city."""
    print(f"[debug] get_weather called with city: {city}")
    choices = ["sunny", "cloudy", "rainy", "snowy"]
    return f"The weather in {city} is {random.choice(choices)}."


spanish_agent = Agent(
    name="Spanish",
    handoff_description="A spanish speaking agent.",
    instructions=prompt_with_handoff_instructions(
        "You're speaking to a human, so be polite and concise. Speak in Spanish.",
    ),
    model="gpt-4.1",
)

agent = Agent(
    name="Assistant",
    instructions=prompt_with_handoff_instructions(
        "You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.",
    ),
    model="gpt-4.1",
    handoffs=[spanish_agent],
    tools=[get_weather],
)


async def main():
    pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))
    buffer = np.zeros(24000 * 3, dtype=np.int16)
    audio_input = AudioInput(buffer=buffer)

    result = await pipeline.run(audio_input)

    # Create an audio player using `sounddevice`
    player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)
    player.start()

    # Play the audio stream as it comes in
    async for event in result.stream():
        if event.type == "voice_stream_event_audio":
            player.write(event.data)


if __name__ == "__main__":
    asyncio.run(main())
```

ì´ ì˜ˆì œë¥¼ ì‹¤í–‰í•˜ë©´ ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ë§ì„ ê²ë‹ˆë‹¤! ì§ì ‘ ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•  ìˆ˜ ìˆëŠ” ë°ëª¨ëŠ” [examples/voice/static](https://github.com/openai/openai-agents-python/tree/main/examples/voice/static)ì—ì„œ í™•ì¸í•˜ì„¸ìš”.