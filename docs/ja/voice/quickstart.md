---
search:
  exclude: true
---
# ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

## å‰ææ¡ä»¶

ã¾ãšã€ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ [Quickstart ã®æ‰‹é †](../quickstart.md) ã«å¾“ã£ã¦  Agents SDK  ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã€ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ãã®å¾Œã€SDK ã®éŸ³å£°é–¢é€£ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```bash
pip install 'openai-agents[voice]'
```

## ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

ã“ã“ã§æŠ¼ã•ãˆã¦ãŠãã¹ãä¸»è¦ãªæ¦‚å¿µã¯ [`VoicePipeline`][agents.voice.pipeline.VoicePipeline] ã§ã™ã€‚ã“ã‚Œã¯æ¬¡ã® 3 ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰æˆã‚Šã¾ã™ã€‚

1. éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹  speech-to-text  ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹  
2. é€šå¸¸ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ãªã‚‹ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã€å®Ÿè¡Œçµæœã‚’ç”Ÿæˆã™ã‚‹  
3. ãã®çµæœãƒ†ã‚­ã‚¹ãƒˆã‚’å†ã³éŸ³å£°ã«å¤‰æ›ã™ã‚‹  text-to-speech  ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹  

```mermaid
graph LR
    %% Input
    A["ğŸ¤ Audio Input"]

    %% Voice Pipeline
    subgraph Voice_Pipeline [Voice Pipeline]
        direction TB
        B["Transcribe (speech-to-text)"]
        C["Your Code"]:::highlight
        D["Text-to-speech"]
        B --> C --> D
    end

    %% Output
    E["ğŸ§ Audio Output"]

    %% Flow
    A --> Voice_Pipeline
    Voice_Pipeline --> E

    %% Custom styling
    classDef highlight fill:#ffcc66,stroke:#333,stroke-width:1px,font-weight:700;

```

## ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ã¾ãšã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã„ãã¤ã‹è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚ã™ã§ã«ã“ã® SDK ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ãŸã“ã¨ãŒã‚ã‚Œã°ã€é¦´æŸ“ã¿ã®ã‚ã‚‹æµã‚Œã®ã¯ãšã§ã™ã€‚ã“ã“ã§ã¯è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ãƒãƒ³ãƒ‰ã‚ªãƒ•ã€ãã—ã¦ãƒ„ãƒ¼ãƒ«ã‚’ç”¨æ„ã—ã¾ã™ã€‚

```python
import asyncio
import random

from agents import (
    Agent,
    function_tool,
)
from agents.extensions.handoff_prompt import prompt_with_handoff_instructions



@function_tool
def get_weather(city: str) -> str:
    """Get the weather for a given city."""
    print(f"[debug] get_weather called with city: {city}")
    choices = ["sunny", "cloudy", "rainy", "snowy"]
    return f"The weather in {city} is {random.choice(choices)}."


spanish_agent = Agent(
    name="Spanish",
    handoff_description="A spanish speaking agent.",
    instructions=prompt_with_handoff_instructions(
        "You're speaking to a human, so be polite and concise. Speak in Spanish.",
    ),
    model="gpt-4o-mini",
)

agent = Agent(
    name="Assistant",
    instructions=prompt_with_handoff_instructions(
        "You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.",
    ),
    model="gpt-4o-mini",
    handoffs=[spanish_agent],
    tools=[get_weather],
)
```

## éŸ³å£°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

[`SingleAgentVoiceWorkflow`][agents.voice.workflow.SingleAgentVoiceWorkflow] ã‚’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã—ã¦ç”¨ã„ãŸã€ã‚·ãƒ³ãƒ—ãƒ«ãªéŸ³å£°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è¨­å®šã—ã¾ã™ã€‚

```python
from agents.voice import SingleAgentVoiceWorkflow, VoicePipeline
pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))
```

## ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ

```python
import numpy as np
import sounddevice as sd
from agents.voice import AudioInput

# For simplicity, we'll just create 3 seconds of silence
# In reality, you'd get microphone data
buffer = np.zeros(24000 * 3, dtype=np.int16)
audio_input = AudioInput(buffer=buffer)

result = await pipeline.run(audio_input)

# Create an audio player using `sounddevice`
player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)
player.start()

# Play the audio stream as it comes in
async for event in result.stream():
    if event.type == "voice_stream_event_audio":
        player.write(event.data)

```

## çµ±åˆ

```python
import asyncio
import random

import numpy as np
import sounddevice as sd

from agents import (
    Agent,
    function_tool,
    set_tracing_disabled,
)
from agents.voice import (
    AudioInput,
    SingleAgentVoiceWorkflow,
    VoicePipeline,
)
from agents.extensions.handoff_prompt import prompt_with_handoff_instructions


@function_tool
def get_weather(city: str) -> str:
    """Get the weather for a given city."""
    print(f"[debug] get_weather called with city: {city}")
    choices = ["sunny", "cloudy", "rainy", "snowy"]
    return f"The weather in {city} is {random.choice(choices)}."


spanish_agent = Agent(
    name="Spanish",
    handoff_description="A spanish speaking agent.",
    instructions=prompt_with_handoff_instructions(
        "You're speaking to a human, so be polite and concise. Speak in Spanish.",
    ),
    model="gpt-4o-mini",
)

agent = Agent(
    name="Assistant",
    instructions=prompt_with_handoff_instructions(
        "You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.",
    ),
    model="gpt-4o-mini",
    handoffs=[spanish_agent],
    tools=[get_weather],
)


async def main():
    pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))
    buffer = np.zeros(24000 * 3, dtype=np.int16)
    audio_input = AudioInput(buffer=buffer)

    result = await pipeline.run(audio_input)

    # Create an audio player using `sounddevice`
    player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)
    player.start()

    # Play the audio stream as it comes in
    async for event in result.stream():
        if event.type == "voice_stream_event_audio":
            player.write(event.data)


if __name__ == "__main__":
    asyncio.run(main())
```

ã“ã®ä¾‹ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚ãªãŸã«è©±ã—ã‹ã‘ã¦ãã¾ã™ã€‚å®Ÿéš›ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ä¼šè©±ã§ãã‚‹ãƒ‡ãƒ¢ã¯ã€[examples/voice/static](https://github.com/openai/openai-agents-python/tree/main/examples/voice/static) ã«ã‚ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚